# PRD — data-lagoon (import path: `lagoon`)
**Tagline:** *Lagoon — a unified Python SDK to discover, read, write, query, and manage Unity Catalog tables across Delta, Iceberg, and Parquet.*

---

## 1) Vision & Motivation
Modern lakehouse stacks mix multiple table formats (Delta, Iceberg, Parquet) and engines (PyIceberg, Delta-RS, DuckDB, Polars, DataFusion, Ibis). Unity Catalog (UC) provides governance and a single namespace, but working across formats still requires different libraries and APIs.

**data-lagoon** provides a **single, typed Python interface** to operate on **Unity Catalog–registered tables** by **name** (`catalog.schema.table`), not by raw storage paths, while choosing the **best underlying engine** automatically for the requested operation.

**Primary goals:**
- Name-first UX: manipulate tables via `catalog.schema.table` in Unity Catalog (no raw `s3://`).
- Format-aware routing: Delta → delta-rs; Iceberg → PyIceberg; Parquet → PyArrow.
- Lightweight SQL and expression query layer (DuckDB/DataFusion/Ibis).
- S3-compatible backends (SeaweedFS, MinIO, R2) supported via one shared config helper.

---

## 2) Objectives
- **Unified API:** `Lagoon.read()`, `Lagoon.write()`, `Lagoon.sql()`, `Lagoon.get_table()`, `Lagoon.describe()`.
- **Catalog-aware:** Resolve table metadata (format, storage location, schema) via **UC REST**.
- **Format-aware:** Route to specific adapters (Delta, Iceberg, Parquet) for IO.
- **Query layer:** Provide SQL across formats using DuckDB; optional DataFusion; Ibis expressions.
- **Interchange:** Prefer **PyArrow Table** or **Polars DataFrame** for returns; avoid Pandas in core.
- **OSS-first:** Target **OSS Unity Catalog**; compatible with managed UC where possible.
- **S3-compatible:** Centralized config for endpoint, path-style, region, credentials.
- **DX:** Fully typed, tests-first, small modules, excellent docstrings.

---

## 3) Scope
### In-scope
- CRUD for catalogs/schemas/tables **via UC REST** (minimal path for MVP).
- List/describe UC tables; resolve schema and storage location.
- Read/write/query for Delta, Iceberg, Parquet.
- Register existing path as **external** table in UC (MVP via helper).
- Optional **Iceberg create** via UC **Iceberg REST** catalog; **Delta** create via delta-rs writers.
- SQL queries via DuckDB; DataFusion optional.
- S3-compatible support including **SeaweedFS** / **MinIO** / **R2**.

### Out-of-scope (initially)
- Row/column level ACL beyond UC enforcement.
- Spark integration (could be a future adapter).
- Workflow/orchestration (Airflow/Prefect).
- Advanced governance (lineage authoring, audits) beyond UC REST reads.

---

## 4) Core Assumptions & Gotchas
- **UC vs data storage:** UC holds metadata; data files live in object storage. Lagoon uses UC to resolve **names → locations** and **formats**.
- **Iceberg:** Prefer **creating/altering tables** via **Iceberg REST catalog** (UC implements this). Reads/writes use PyIceberg; SQL via DuckDB reading Iceberg where supported.
- **Delta:** Use **delta-rs (deltalake)** for reads/writes. Name-based loads via `uc://catalog.schema.table` (for managed & OSS where supported). For writes/creates, Lagoon may need to **resolve location from UC first** then write.
- **Parquet:** Not a “table format” with a catalog protocol. Parquet tables are UC **external tables** pointing to a folder; Lagoon resolves location via UC then uses **PyArrow**/Polars for IO.
- **CSV/JSON:** Treated as external tables pointing to a folder; Lagoon resolves location via UC then uses **PyArrow**, **Polars** or **DuckDB** (configured by user) for IO.
- **S3-compatible:** Always set **endpoint**, **path-style** addressing, **region**, and credentials. Some engines require env vars, others accept `storage_options`/config objects.
- **Consistency semantics:** S3-compatible stores differ. Ensure listing/writes are visible before reads (refresh if necessary). Be explicit about **eventual consistency** gotchas.
- **Refresh semantics:** For Parquet/Delta/Iceberg, after external writes, some engines cache listings. Provide `Lagoon.refresh(table)` helper to re-list/clear caches when needed.
- **Compression & partitioning:** Leave to engines with explicit kwargs; Lagoon will pass through options where reasonable.
- **Large data:** Favor **lazy** reading (scans) and **projection/predicate pushdown** where engine supports it.

---

## 5) System Architecture
```
+---------------------------------------------------+
|                 lagoon (Facade)                   |
|  Lagoon.read/write/sql/get_table/describe         |
+-------------------------+-------------------------+
                          |
                          v
+---------------------------------------------------+
|         Dispatcher (format & capability)          |
|  Inspect metadata (via UC) -> choose adapter      |
+-------------------------+-------------------------+
         | Delta                 | Iceberg                 | Parquet
         v                       v                         v
+----------------+     +---------------------+     +------------------+
| Delta Adapter  |     | PyIceberg Adapter   |     | PyArrow Adapter  |
| (delta-rs)     |     | (Iceberg REST + IO) |     | (Parquet IO)     |
+----------------+     +---------------------+     +------------------+
                          ^
                          |
                 +------------------+
                 |  Query Engines   |
                 | DuckDB / Fusion  |
                 +------------------+
                          ^
                          |
                 +------------------+
                 |  UC REST Client  |
                 |  (tables, meta)  |
                 +------------------+

Storage: S3/S3-compatible (SeaweedFS, MinIO), R2, local FS
```

---

## 6) Public API (Python)
```python
from lagoon import Lagoon

lg = Lagoon(
    uc_url="http://localhost:8080",
    s3_endpoint="http://seaweed-s3:8333",
    s3_region="us-east-1",
    access_key="...",
    secret_key="...",
    path_style=True,
)

# Name-first access
t = lg.get_table("unity.default.sales")   # BaseTable facade
df_polars = t.to_polars()
tbl_arrow = t.to_arrow()

# Write (create if missing depending on adapter format)
lg.write(df_polars, "unity.default.sales_copy", format="delta", mode="overwrite")

# SQL across formats
res = lg.sql("""
SELECT d.id, i.name
FROM unity.default.delta_demo d
JOIN unity.default.iceberg_demo i USING (id)
WHERE d.price > 100
LIMIT 100
""")

# Metadata helpers
lg.describe("unity.default.sales")
lg.list_tables("unity.default")
lg.drop_table("unity.default.temp_table")

# Register external path as UC table (MVP)
lg.register(path="s3://bucket/path/", as_table="unity.default.logs", format="parquet")
```

---

## 7) Detailed Design

### 7.1 Lagoon Facade
- **Constructor kwargs**: `uc_url`, `s3_endpoint`, `path_style`, `s3_region`, `access_key`, `secret_key`, `duckdb_config`.
- **Methods**:
  - `get_table(full_name) -> BaseTable`
  - `read(full_name) -> BaseTable`
  - `write(df, full_name, format, mode="append", **options) -> None`
  - `sql(sql_text, *, backend="duckdb") -> Arrow/Polars`
  - `describe(full_name) -> dict`
  - `list_tables("catalog.schema" | catalog, schema) -> list[dict]`
  - `drop_table(full_name) -> None`
  - `register(path, as_table, format, columns=None) -> None`
  - `refresh(full_name) -> None` (engine-specific cache invalidation)

### 7.2 UC REST Client
- `/api/2.1/unity-catalog/tables/{full_name}` → get table metadata.
- List tables by catalog+schema.
- Create minimal external table (MVP) for Parquet/Delta path.
- Drop table.

### 7.3 Dispatcher
- Input: `TableMetadata` (format, storage_location).
- Format routing:
  - **DELTA** → `DeltaAdapter(storage_location)`
  - **ICEBERG** → `IcebergAdapter(full_name)` via UC Iceberg REST catalog
  - **PARQUET** → `ParquetAdapter(storage_location)`
- Unknown format: raise `UnsupportedFormatError`.

### 7.4 Adapters
#### Delta Adapter (delta-rs)
- `to_arrow()`: `DeltaTable(storage_location).to_pyarrow_table()`
- `to_polars()`: via Arrow conversion.
- `write(df, mode)`: `write_deltalake(storage_location, df, mode=...)` + storage options.
- `delete(where)`: best-effort via delta-rs if supported; otherwise raise `NotImplementedError`.
- Name-first read: support `DeltaTable("uc://catalog.schema.table")` when available; else resolve path via UC first.

#### Iceberg Adapter (PyIceberg)
- Configured against **UC Iceberg REST** endpoint.
- `create_table(identifier, schema)` via PyIceberg catalog.
- `load_table(identifier)`, appends via Arrow writer utilities.
- IO: `to_arrow()` via PyIceberg readers; `to_polars()` via Arrow→Polars.
- Writes: append/overwrite APIs when supported; fall back to write-then-commit patterns.
- Deletion: use Iceberg delete semantics if/when exposed; otherwise raise clearly.

#### Parquet Adapter (PyArrow)
- `to_arrow()`: dataset scan with projection/predicate options.
- `to_polars()`: Arrow→Polars.
- `write(df, mode)`: write one/many Parquet files (respect partitioning if provided); `mode="overwrite"` clears directory (guard prompts optional).
- `delete(where)`: not supported generically; raise with guidance.

### 7.5 Query Engines
- **DuckDB** (default): UC name resolution → location; attach UC catalog if extension available (best effort). Otherwise, substitute resolved paths into views and run SQL.
- **DataFusion** (optional): Provide a backend for local/distributed SQL; prioritize Arrow interoperability.
- **Ibis**: Expression builder; compile to DuckDB engine or DataFusion backend.

---

## 8) Storage & Credentials (S3-compatible)
**Single helper** provides config for all adapters:
- `endpoint`, `region`, `access_key`, `secret_key`, `path_style`, `use_ssl` (derive from endpoint).
- Expose as:
  - `storage_options` dict (delta-rs, pyarrow)
  - Env vars (delta-rs: `AWS_ENDPOINT_URL`, `AWS_REGION`, …)
  - PyIceberg catalog config (`s3.endpoint`, `s3.path-style-access`)

**SeaweedFS S3 defaults:**
- Endpoint: `http://seaweed-s3:8333`
- Path-style: `true`
- Region: `us-east-1`
- SSL: `false`

---

## 9) Errors & Diagnostics
- Precise exception classes: `CatalogError`, `UnsupportedFormatError`, `WriteError`, `QueryError`.
- UC HTTP errors propagated with status code and endpoint.
- Adapters wrap engine-specific exceptions with context (table name, operation).
- Structured logging with operation, table, duration, row counts.

---

## 10) Performance & Consistency
- Favor **scan/lazy** interfaces; avoid materializing large frames unless requested.
- Pushdown: projection & predicate pushdown where engine supports it.
- Consistency: expose `refresh()` to re-list object storage when needed.
- Parallel writes: optional parameters for Parquet/Delta writers; document limits.

---

## 11) Security
- Credentials injected only at runtime; never persisted in logs.
- Support custom CA / TLS for endpoints.
- Token-based UC auth pluggable (OSS UC often no-auth in dev; managed UC needs tokens).

---

## 12) Testing Strategy
- **Unit tests** for UC client with `respx` (200/4xx paths).
- **Adapter tests** with temp directories and/or mocked S3 endpoints.
- Round-trip tests: write → read → assert schema & row counts.
- Contract tests: ensure `BaseTable` methods behave the same across formats.

---

## 13) Non-Functional Requirements
- Python 3.10+, typed APIs, ruff + mypy clean.
- Clear module boundaries; minimal dependencies.
- Apache-2.0 licensing; attribution in docs.
- CI: run `ruff`, `mypy`, `pytest` on PRs.

---

## 14) Roadmap / Phases
**Phase 1** (DONE): Core scaffolding + UC REST + dispatcher + tests.  
**Phase 2**: Delta & Parquet adapters + S3 helper + round-trip tests.  
**Phase 3**: PyIceberg adapter via UC Iceberg REST + DuckDB SQL + Lagoon facade.  
**Phase 4**: DataFusion & Ibis + backend selector + CLI + docs.  
**Phase 5**: Optimizations (pushdown hints, cache), lineage reads, optional Spark adapter.

---

## 15) Reference Directory Layout
```
src/lagoon/
  __init__.py        # export Lagoon facade
  core.py            # BaseTable, TableMetadata
  client.py          # UC REST client
  dispatch.py        # routing
  adapters/
    base.py
    delta_rs.py
    pyiceberg_.py
    pyarrow_.py
    polars_.py
    duckdb_.py
    datafusion_.py
    ibis_.py
tests/
  test_client.py
  test_dispatch.py
  adapters/
    test_delta_rs.py
    test_pyarrow.py
    test_pyiceberg.py
docs/architecture/
  README.md
  decisions.md
```

---

## 16) Minimal Type Signatures (selected)
```python
# core.py
@dataclass
class TableMetadata:
    full_name: str
    data_source_format: str   # "DELTA" | "ICEBERG" | "PARQUET"
    storage_location: str
    schema_json: dict | None = None

class BaseTable:
    def to_arrow(self) -> "pyarrow.Table": ...
    def to_polars(self) -> "polars.DataFrame": ...
    def write(self, df, mode: str = "append") -> None: ...
    def delete(self, where: str | None = None) -> None: ...

# adapters/base.py
class TableAdapter(Protocol):
    storage_location: str | None
    format: str
    def to_arrow(self): ...
    def to_polars(self): ...
    def write(self, df, mode: str = "append"): ...
    def delete(self, where: str | None = None): ...

# client.py
class UCClient:
    def get_table(self, full_name: str) -> dict: ...
    def list_tables(self, catalog: str, schema: str) -> list[dict]: ...
    def create_external_table(self, full_name: str, format: str, storage_location: str, columns: list[dict] | None = None) -> dict: ...
    def drop_table(self, full_name: str) -> None: ...

# facade
class Lagoon:
    def get_table(self, full_name: str) -> BaseTable: ...
    def read(self, full_name: str) -> BaseTable: ...
    def write(self, df, full_name: str, format: str, mode: str = "append", **options) -> None: ...
    def sql(self, sql_text: str, *, backend: str = "duckdb"): ...
    def describe(self, full_name: str) -> dict: ...
    def list_tables(self, qualified: str | None = None, *, catalog: str | None = None, schema: str | None = None) -> list[dict]: ...
    def drop_table(self, full_name: str) -> None: ...
    def register(self, path: str, as_table: str, format: str, columns: list[dict] | None = None) -> None: ...
    def refresh(self, full_name: str) -> None: ...
```

---

## 17) Name-based Operations vs Paths
- **Iceberg:** rely on **UC Iceberg REST** catalog to create/load by name.
- **Delta:** load by `uc://...` where supported; otherwise use UC REST to map name → `storage_location` then operate by path.
- **Parquet:** always resolve via UC REST; Parquet tables are external folders. For appends, write Parquet files to the resolved folder and call `refresh()` if needed.

---

## 18) S3 Options Matrix (cheatsheet)
| Engine    | Endpoint option                            | Path-style | SSL          |
| --------- | ------------------------------------------ | ---------- | ------------ |
| delta-rs  | env: `AWS_ENDPOINT_URL`, `AWS_REGION`      | implicit   | via URL      |
| pyarrow   | `S3FileSystem(endpoint_override=…)`        | automatic  | via URL      |
| pyiceberg | `s3.endpoint`, `s3.path-style-access`      | explicit   | via URL      |
| duckdb    | `SET s3_endpoint=…`, `s3_url_style='path'` | explicit   | `s3_use_ssl` |

---

## 19) Examples (concise)

### Delta write via name-first
```python
tbl = lg.get_table("unity.default.delta_demo")
# resolve path internally; write using delta-rs
lg.write(df, "unity.default.delta_demo", format="delta", mode="append")
```

### Iceberg create via UC Iceberg REST (PyIceberg)
```python
lg.iceberg.catalog.create_table("unity.default.iceberg_new", schema=...)
```

### Parquet append via UC path
```python
lg.write(df, "unity.default.parquet_demo", format="parquet", mode="append")
lg.refresh("unity.default.parquet_demo")
```

---

## 20) Future Enhancements
- Pushdown planner to choose best engine per query (cost-based).
- Lineage reads & simple write-ahead logging (WAL) for risky ops.
- Secrets providers (env, file, cloud secrets).
- Spark adapter and dbt/sqlmesh integrations.
